# [Reflective Activity 1 – Ethics in Computing in the age of Generative AI](RMPP_Unit01_Activity.pdf)

_(Word count: 1,015)_

In recent years, the swift emergence of generative artificial intelligence (AI) has significantly reshaped everyday life, from online communication to new forms of creative expression. Although AI as a concept is not completely new, the sheer speed and scope of recent developments have prompted a fresh examination of ethical, legal, and professional frameworks. With the introduction of large-scale models, there is widespread debate about how best to govern AI’s continued expansion.

Correa et al. (2023) note that while a great deal of work has gone into defining broad AI principles, achieving genuine consensus is challenging. Different regions, sectors, and stakeholders hold divergent views on what AI should achieve or be allowed to do. As a result, researchers, government bodies, and private organisations are trying to create global guidelines that remain adaptable to local circumstances. Nevertheless, this is no small feat; even widely proposed values like *trustworthiness* can be difficult to translate into concrete national or corporate policies.

Deckard (2023) makes a similar argument, stressing that AI ethics is not solely a Western or academic topic. Rather, nations worldwide must tackle new generative tools that could unsettle areas such as journalism, law, and the creative industry. This *AI boom* has already reached numerous lower-income and middle-income countries, stirring discussions about whether wealthy nations dominate policy agendas and risk overlooking local realities elsewhere.

Such debates arise in the realm of data protection frameworks across different parts of the world. In the European Union, the General Data Protection Regulation (GDPR) is frequently praised as one of the foremost structures for safeguarding personal data rights (FSDC, 2022). A 2020 report from the European Parliamentary Research Service (EPRS, 2020) highlights GDPR’s positive features—such as data minimisation and transparency—and the difficulties involved in applying these rules to emerging AI. Many small-to-medium enterprises find compliance hard to achieve, and critics contend that GDPR’s reliance on consent does not adequately cover the ways in which generative AI can generate insights beyond the original scope. Still, GDPR preserves individuals’ right to erasure, which could help manage model training and updates.

Likewise, frameworks such as Hong Kong’s Personal Data (Privacy) Ordinance (PDPO) offer guidance on best practices in data protection and transparency. Hong Kong’s Privacy Commissioner for Personal Data (PCPD, 2021) published the “Guidance on the Ethical Development and Use of Artificial Intelligence,” promoting principles like accountability, fairness, and respect for individual rights. While these guidelines are not legally binding, they overlap with several European standards emphasising data privacy. Nevertheless, local differences remain clear. Hong Kong’s PDPO is traditionally narrower, concentrating on personal data control rather than, for instance, the right to explanation in automated decision-making (Hagen, 2021). These variations point to the need for international cooperation that still takes into account the unique conditions of each region.

Correa et al. (2023) further observe that most AI ethics policies rely on self-regulation or industry leadership, with only a minority advocating enforced regulations. Relying on entirely voluntary approaches may be inadequate for preventing issues like data exploitation, disinformation, and biased outcomes. If corporations focus primarily on revenue, fairness and public welfare could be disregarded. This is especially worrying for marginalised communities, who may have little recourse if an opaque algorithm unjustly blocks their access to healthcare, jobs, or other essential services.

Looking to the future, governments, experts, and major technology firms could apply a multi-pronged approach:
1. **Transparent Standards**: Greater openness is vital. Systems used in sensitive domains like finance, healthcare, and policing should be able to undergo auditing by independent specialists or regulators (Correa et al., 2023).  

2. **Sector-Specific Laws**: A single, universal regulation may not suit every area. Healthcare AI raises pressing questions about patient privacy, and AI-based hiring systems risk discrimination if they are not adequately checked. GDPR-like data protections might pair well with stricter guidelines for criminal justice and surveillance.  

3. **Practical Tools**: As Deckard (2023) remarks, ethical frameworks are of limited value if they lack tangible methods for implementation. Tools that measure carbon emissions or check for hidden biases in machine-learning models could become standard in development pipelines to minimise detrimental effects.  

4. **Balanced Intellectual Property**: AI’s expansion can create tension between openness and proprietary interests. As Correa et al. (2023) suggest, “cooperation/fair competition” might be supported by frameworks allowing partial or time-limited open access to model features, enabling small entities to innovate while respecting commercial interests.  

5. **Inclusive Governance**: Because the perks and downsides of generative AI are unequally shared, diversity and inclusion are essential. In the UK, bodies like the British Computer Society (BCS) could consult with disability groups or regional community leaders to include a wider range of perspectives when drafting guidelines.  

6. **Adaptive Legislation**: The upcoming EU AI Act is a helpful starting point, though it mostly addresses risks. Incorporating short- and long-term concerns, like algorithmic bias and possible job disruption, calls for collaboration between regulators and the private sector. Accountability must extend through research, development, and deployment phases.  

From a social perspective, stronger oversight of extensive AI systems may raise compliance costs and affect smaller firms’ competitiveness. Still, leaving major providers of large language models to regulate themselves is precarious. Trust in generative AI requires demonstrating fairness, respect for privacy, and supportive approaches to intellectual property.

From a professional standpoint, such measures could influence how computer scientists are trained. University curricula might include courses on transparent model design, inclusive AI practices, and data ethics. This cross-disciplinary teaching would join computing with law, social sciences, and humanities, widening students’ awareness of the societal consequences of AI systems.

In conclusion, it is insufficient to rely on improvised ethical guidelines without legal or organisational reinforcement. Stronger, field-specific, and legally binding standards are required, grounded in widely recognised principles: transparency, fairness, reliability, and accountability. As the UK refines its regulatory stance, harnessing the benefits of GDPR while confronting problems such as disinformation and bias may be the most promising course. By ensuring that governments, developers, users, and affected communities all have a voice in these discussions, we can capitalise on the extraordinary potential of generative AI (Reyneke, 2023) while honouring the ethical, legal, and professional obligations it entails.
<br><br>


### References
Correa, N.K., Galvão, C., Santos, J.W., Del Pino, C., Pinto, E.P., Barbosa, C., Massmann, D., Mambrini, R., Galvão, L., Terem, E. & de Oliveira, N. (2023) ‘Worldwide AI ethics: A review of 200 guidelines and recommendations for AI governance’, Patterns 4(10): 100857. Available from: https://doi.org/10.1016/j.patter.2023.100857 [Accessed 1 February 2025].

Deckard, R. (2023) What are ethics in AI? BCS – The Chartered Institute for IT. Available from: https://www.bcs.org/articles-opinion-and-research/what-are-ethics-in-ai/ [Accessed 2 February 2025].

European Parliamentary Research Service (EPRS) (2020) The impact of the General Data Protection Regulation (GDPR) on artificial intelligence. Available from: https://www.europarl.europa.eu/RegData/etudes/STUD/2020/641530/EPRS_STU(2020)641530_EN.pdf [Accessed 8 February 2025].

FSDC. (2022) _Connecting Data: Establishing Hong Kong as a Cross-Boundary Financial Data Hub_. Available from: https://www.fsdc.org.hk/en/insights/connecting-data-establishing-hong-kong-as-a-cross-boundary-financial-data-hub [Accessed 1 February 2025].

Hagen, G. (2021) ‘AI and Patents and Trade Secrets’, in: Bariteau, F.M. & Scassa, T. (eds)  _Artificial Intelligence and the Law in Canada. Toronto: LexisNexis Canada_. Available at SSRN: https://ssrn.com/abstract=3734654 [Accessed 8 February 2025]

Reyneke, J.A. (2023) Ethics and Implications of Artificial Intelligence: Navigating the Path to Responsible Innovation. Available from: https://medium.com/aimonks/ethics-and-implications-of-artificial-intelligence-navigating-the-path-to-responsible-innovation-9738d0bd8a2b [Accessed 6 February 2025]

Office of the Privacy Commissioner for Personal Data (PCPD) (2021) Guidance on the ethical development and use of artificial intelligence. Hong Kong: PCPD. Available from: https://www.pcpd.org.hk/english/resources_centre/publications/files/guidance_ethical_e.pdf  [Accessed 6 February 2025].

### Bibliography
Fjeld, J., Achten, N., Hilligoss, H., Nagy, A.C. & Srikumar, M. (2020) Principled Artificial Intelligence: Mapping Consensus in Ethical and Rights-Based Approaches to Principles for AI. Cambridge, MA: Berkman Klein Center for Internet & Society. Available from: https://cyber.harvard.edu/publication/2020/principled-ai [Accessed 2 February 2025].

<br><br>

---

### Reflections
Generative AI, such as large language models, has transformed industries by enabling new forms of creativity and problem-solving. While these advancements are exciting, they also come with significant ethical concerns. For example, generative AI can inadvertently perpetuate biases in datasets, produce misleading information, or violate individual privacy. I learned that frameworks like the EU’s General Data Protection Regulation (GDPR) and Hong Kong’s Personal Data (Privacy) Ordinance (PDPO) aim to address these challenges, but they often struggle to keep pace with the speed of AI development.

Reflecting on this, I realised the critical role of computer scientists in designing systems that prioritise fairness, accountability, and transparency. This activity also highlighted the growing need for interdisciplinary collaboration between computer science, law, and social sciences to address the societal impacts of AI technologies.

<br><br>

---
[Return to Module 7 Unit 1](RMPP_Unit01.md)
